{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "58145890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e19d21bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pclass', 'survived', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket',\n",
       "       'fare', 'cabin', 'embarked', 'boat', 'body', 'home.dest'],\n",
       "      dtype='str')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"titanic.csv\")\n",
    "# print(df.head())\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8ac42c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Anderson, Mr. Harry</td>\n",
       "      <td>male</td>\n",
       "      <td>48.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19952</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>E12</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Miss. Kornelia Theodosia</td>\n",
       "      <td>female</td>\n",
       "      <td>63.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13502</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>D7</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hudson, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Andrews, Mr. Thomas Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>39.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A36</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Belfast, NI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Appleton, Mrs. Edward Dale (Charlotte Lamson)</td>\n",
       "      <td>female</td>\n",
       "      <td>53.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11769</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>C101</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bayside, Queens, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Artagaveytia, Mr. Ramon</td>\n",
       "      <td>male</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17609</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Montevideo, Uruguay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "5       1         1                              Anderson, Mr. Harry    male   \n",
       "6       1         1                Andrews, Miss. Kornelia Theodosia  female   \n",
       "7       1         0                           Andrews, Mr. Thomas Jr    male   \n",
       "8       1         1    Appleton, Mrs. Edward Dale (Charlotte Lamson)  female   \n",
       "9       1         0                          Artagaveytia, Mr. Ramon    male   \n",
       "\n",
       "     age  sibsp  parch    ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.00      0      0     24160  211.3375       B5        S    2    NaN   \n",
       "1   0.92      1      2    113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.00      1      2    113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.00      1      2    113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.00      1      2    113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "5  48.00      0      0     19952   26.5500      E12        S    3    NaN   \n",
       "6  63.00      1      0     13502   77.9583       D7        S   10    NaN   \n",
       "7  39.00      0      0    112050    0.0000      A36        S  NaN    NaN   \n",
       "8  53.00      2      0     11769   51.4792     C101        S    D    NaN   \n",
       "9  71.00      0      0  PC 17609   49.5042      NaN        C  NaN   22.0   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  \n",
       "5                     New York, NY  \n",
       "6                       Hudson, NY  \n",
       "7                      Belfast, NI  \n",
       "8              Bayside, Queens, NY  \n",
       "9              Montevideo, Uruguay  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "443d1abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9,10]\n",
    "mean = 5\n",
    "median = 5.5\n",
    "mode = 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "79e3305a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pclass     1309 non-null   int64  \n",
      " 1   survived   1309 non-null   int64  \n",
      " 2   name       1309 non-null   str    \n",
      " 3   sex        1309 non-null   str    \n",
      " 4   age        1046 non-null   float64\n",
      " 5   sibsp      1309 non-null   int64  \n",
      " 6   parch      1309 non-null   int64  \n",
      " 7   ticket     1309 non-null   str    \n",
      " 8   fare       1308 non-null   float64\n",
      " 9   cabin      295 non-null    str    \n",
      " 10  embarked   1307 non-null   str    \n",
      " 11  boat       486 non-null    str    \n",
      " 12  body       121 non-null    float64\n",
      " 13  home.dest  745 non-null    str    \n",
      "dtypes: float64(3), int64(4), str(7)\n",
      "memory usage: 210.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cb5cbace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.keys of       pclass  survived                                             name  \\\n",
       "0          1         1                    Allen, Miss. Elisabeth Walton   \n",
       "1          1         1                   Allison, Master. Hudson Trevor   \n",
       "2          1         0                     Allison, Miss. Helen Loraine   \n",
       "3          1         0             Allison, Mr. Hudson Joshua Creighton   \n",
       "4          1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)   \n",
       "...      ...       ...                                              ...   \n",
       "1304       3         0                             Zabour, Miss. Hileni   \n",
       "1305       3         0                            Zabour, Miss. Thamine   \n",
       "1306       3         0                        Zakarian, Mr. Mapriededer   \n",
       "1307       3         0                              Zakarian, Mr. Ortin   \n",
       "1308       3         0                               Zimmerman, Mr. Leo   \n",
       "\n",
       "         sex    age  sibsp  parch  ticket      fare    cabin embarked boat  \\\n",
       "0     female  29.00      0      0   24160  211.3375       B5        S    2   \n",
       "1       male   0.92      1      2  113781  151.5500  C22 C26        S   11   \n",
       "2     female   2.00      1      2  113781  151.5500  C22 C26        S  NaN   \n",
       "3       male  30.00      1      2  113781  151.5500  C22 C26        S  NaN   \n",
       "4     female  25.00      1      2  113781  151.5500  C22 C26        S  NaN   \n",
       "...      ...    ...    ...    ...     ...       ...      ...      ...  ...   \n",
       "1304  female  14.50      1      0    2665   14.4542      NaN        C  NaN   \n",
       "1305  female    NaN      1      0    2665   14.4542      NaN        C  NaN   \n",
       "1306    male  26.50      0      0    2656    7.2250      NaN        C  NaN   \n",
       "1307    male  27.00      0      0    2670    7.2250      NaN        C  NaN   \n",
       "1308    male  29.00      0      0  315082    7.8750      NaN        S  NaN   \n",
       "\n",
       "       body                        home.dest  \n",
       "0       NaN                     St Louis, MO  \n",
       "1       NaN  Montreal, PQ / Chesterville, ON  \n",
       "2       NaN  Montreal, PQ / Chesterville, ON  \n",
       "3     135.0  Montreal, PQ / Chesterville, ON  \n",
       "4       NaN  Montreal, PQ / Chesterville, ON  \n",
       "...     ...                              ...  \n",
       "1304  328.0                              NaN  \n",
       "1305    NaN                              NaN  \n",
       "1306  304.0                              NaN  \n",
       "1307    NaN                              NaN  \n",
       "1308    NaN                              NaN  \n",
       "\n",
       "[1309 rows x 14 columns]>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cb784df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>14.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>C</td>\n",
       "      <td>328.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>26.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "      <td>304.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass     sex    age  sibsp  parch      fare embarked   body  \\\n",
       "0          1  female  29.00      0      0  211.3375        S    NaN   \n",
       "1          1    male   0.92      1      2  151.5500        S    NaN   \n",
       "2          1  female   2.00      1      2  151.5500        S    NaN   \n",
       "3          1    male  30.00      1      2  151.5500        S  135.0   \n",
       "4          1  female  25.00      1      2  151.5500        S    NaN   \n",
       "...      ...     ...    ...    ...    ...       ...      ...    ...   \n",
       "1304       3  female  14.50      1      0   14.4542        C  328.0   \n",
       "1305       3  female    NaN      1      0   14.4542        C    NaN   \n",
       "1306       3    male  26.50      0      0    7.2250        C  304.0   \n",
       "1307       3    male  27.00      0      0    7.2250        C    NaN   \n",
       "1308       3    male  29.00      0      0    7.8750        S    NaN   \n",
       "\n",
       "                            home.dest  \n",
       "0                        St Louis, MO  \n",
       "1     Montreal, PQ / Chesterville, ON  \n",
       "2     Montreal, PQ / Chesterville, ON  \n",
       "3     Montreal, PQ / Chesterville, ON  \n",
       "4     Montreal, PQ / Chesterville, ON  \n",
       "...                               ...  \n",
       "1304                              NaN  \n",
       "1305                              NaN  \n",
       "1306                              NaN  \n",
       "1307                              NaN  \n",
       "1308                              NaN  \n",
       "\n",
       "[1309 rows x 9 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"survived\", \"name\", \"ticket\", \"cabin\", \"boat\"])\n",
    "y = df[\"survived\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1d8fb512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass     sex    age  sibsp  parch      fare embarked   body  \\\n",
       "0       1  female  29.00      0      0  211.3375        S    NaN   \n",
       "1       1    male   0.92      1      2  151.5500        S    NaN   \n",
       "2       1  female   2.00      1      2  151.5500        S    NaN   \n",
       "3       1    male  30.00      1      2  151.5500        S  135.0   \n",
       "4       1  female  25.00      1      2  151.5500        S    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "900e3499",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"age\", \"fare\", \"sibsp\", \"parch\"]\n",
    "categorical_features = [\"sex\", \"embarked\", \"home.dest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b49523ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"onehot\", pd.get_dummies)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5cf6bf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "Index: 73 entries, 3 to 1089\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pclass     73 non-null     int64  \n",
      " 1   sex        73 non-null     str    \n",
      " 2   age        73 non-null     float64\n",
      " 3   sibsp      73 non-null     int64  \n",
      " 4   parch      73 non-null     int64  \n",
      " 5   fare       73 non-null     float64\n",
      " 6   embarked   73 non-null     str    \n",
      " 7   body       73 non-null     float64\n",
      " 8   home.dest  73 non-null     str    \n",
      "dtypes: float64(3), int64(3), str(3)\n",
      "memory usage: 7.4 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7896\\83591564.py:2: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.\n",
      "\n",
      "See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html\n",
      "  X[\"age\"].fillna(X[\"age\"].median(), inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7896\\83591564.py:3: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.\n",
      "\n",
      "See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html\n",
      "  X[\"embarked\"].fillna(X[\"embarked\"].mode()[0], inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7896\\83591564.py:4: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.\n",
      "\n",
      "See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html\n",
      "  X[\"home.dest\"].fillna(X[\"home.dest\"].mode()[0], inplace=True)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7896\\83591564.py:5: ChainedAssignmentError: A value is being set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "Such inplace method never works to update the original DataFrame or Series, because the intermediate object on which we are setting values always behaves as a copy (due to Copy-on-Write).\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' instead, to perform the operation inplace on the original object, or try to avoid an inplace operation using 'df[col] = df[col].method(value)'.\n",
      "\n",
      "See the documentation for a more detailed explanation: https://pandas.pydata.org/pandas-docs/stable/user_guide/copy_on_write.html\n",
      "  X[\"fare\"].fillna(X[\"fare\"].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Missing values\n",
    "X[\"age\"].fillna(X[\"age\"].median(), inplace=True)\n",
    "X[\"embarked\"].fillna(X[\"embarked\"].mode()[0], inplace=True)\n",
    "X[\"home.dest\"].fillna(X[\"home.dest\"].mode()[0], inplace=True)\n",
    "X[\"fare\"].fillna(X[\"fare\"].median(), inplace=True)\n",
    "# Удаляем строки с оставшимися NaN значениями\n",
    "X = X.dropna()\n",
    "y = y[X.index]\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "73a8b4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "Index: 73 entries, 3 to 1089\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pclass     73 non-null     int64  \n",
      " 1   sex        73 non-null     str    \n",
      " 2   age        73 non-null     float64\n",
      " 3   sibsp      73 non-null     int64  \n",
      " 4   parch      73 non-null     int64  \n",
      " 5   fare       73 non-null     float64\n",
      " 6   embarked   73 non-null     str    \n",
      " 7   body       73 non-null     float64\n",
      " 8   home.dest  73 non-null     str    \n",
      "dtypes: float64(3), int64(3), str(3)\n",
      "memory usage: 7.4 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1da942da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X[numeric_features] = scaler.fit_transform(X[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bfdaceb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass                                     0\n",
       "age                                        0\n",
       "sibsp                                      0\n",
       "parch                                      0\n",
       "fare                                       0\n",
       "                                          ..\n",
       "home.dest_West Kensington, London          0\n",
       "home.dest_Weston-Super-Mare, Somerset      0\n",
       "home.dest_Windsor, England New York, NY    0\n",
       "home.dest_Winnipeg, MB                     0\n",
       "home.dest_Worcester, MA                    0\n",
       "Length: 76, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()  # Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "33e37817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>home.dest_Argentina</th>\n",
       "      <th>...</th>\n",
       "      <th>home.dest_Sweden&nbsp;&nbsp;Worcester, MA</th>\n",
       "      <th>home.dest_Sweden / Arlington, NJ</th>\n",
       "      <th>home.dest_Sydney, Australia</th>\n",
       "      <th>home.dest_Vancouver, BC</th>\n",
       "      <th>home.dest_West Hampstead, London / Neepawa, MB</th>\n",
       "      <th>home.dest_West Kensington, London</th>\n",
       "      <th>home.dest_Weston-Super-Mare, Somerset</th>\n",
       "      <th>home.dest_Windsor, England New York, NY</th>\n",
       "      <th>home.dest_Winnipeg, MB</th>\n",
       "      <th>home.dest_Worcester, MA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.705118</td>\n",
       "      <td>1.185999</td>\n",
       "      <td>2.348632</td>\n",
       "      <td>2.496272</td>\n",
       "      <td>135.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2.238283</td>\n",
       "      <td>-0.617708</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>0.200751</td>\n",
       "      <td>22.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.515317</td>\n",
       "      <td>1.185999</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>4.205331</td>\n",
       "      <td>124.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.064070</td>\n",
       "      <td>-0.617708</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>-0.327976</td>\n",
       "      <td>148.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>0.587107</td>\n",
       "      <td>-0.617708</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>0.223057</td>\n",
       "      <td>208.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pclass       age     sibsp     parch      fare   body  sex_male  \\\n",
       "3        1 -0.705118  1.185999  2.348632  2.496272  135.0      True   \n",
       "9        1  2.238283 -0.617708 -0.351370  0.200751   22.0      True   \n",
       "10       1  0.515317  1.185999 -0.351370  4.205331  124.0      True   \n",
       "25       1 -1.064070 -0.617708 -0.351370 -0.327976  148.0      True   \n",
       "39       1  0.587107 -0.617708 -0.351370  0.223057  208.0      True   \n",
       "\n",
       "    embarked_Q  embarked_S  home.dest_Argentina  ...  \\\n",
       "3        False        True                False  ...   \n",
       "9        False       False                False  ...   \n",
       "10       False       False                False  ...   \n",
       "25       False       False                False  ...   \n",
       "39       False       False                False  ...   \n",
       "\n",
       "    home.dest_Sweden  Worcester, MA  home.dest_Sweden / Arlington, NJ  \\\n",
       "3                             False                             False   \n",
       "9                             False                             False   \n",
       "10                            False                             False   \n",
       "25                            False                             False   \n",
       "39                            False                             False   \n",
       "\n",
       "    home.dest_Sydney, Australia  home.dest_Vancouver, BC  \\\n",
       "3                         False                    False   \n",
       "9                         False                    False   \n",
       "10                        False                    False   \n",
       "25                        False                    False   \n",
       "39                        False                    False   \n",
       "\n",
       "    home.dest_West Hampstead, London / Neepawa, MB  \\\n",
       "3                                            False   \n",
       "9                                            False   \n",
       "10                                           False   \n",
       "25                                           False   \n",
       "39                                           False   \n",
       "\n",
       "    home.dest_West Kensington, London  home.dest_Weston-Super-Mare, Somerset  \\\n",
       "3                               False                                  False   \n",
       "9                               False                                  False   \n",
       "10                              False                                  False   \n",
       "25                              False                                  False   \n",
       "39                              False                                  False   \n",
       "\n",
       "    home.dest_Windsor, England New York, NY  home.dest_Winnipeg, MB  \\\n",
       "3                                     False                   False   \n",
       "9                                     False                   False   \n",
       "10                                    False                   False   \n",
       "25                                    False                   False   \n",
       "39                                    False                   False   \n",
       "\n",
       "    home.dest_Worcester, MA  \n",
       "3                     False  \n",
       "9                     False  \n",
       "10                    False  \n",
       "25                    False  \n",
       "39                    False  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e55df80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "eebf38b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes: [0]\n",
      "Class counts:\n",
      " survived\n",
      "0    73\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check unique values and counts in target variable\n",
    "print(\"Unique classes:\", y.unique())\n",
    "print(\"Class counts:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2daedb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>body</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>home.dest_Argentina</th>\n",
       "      <th>...</th>\n",
       "      <th>home.dest_Sweden&nbsp;&nbsp;Worcester, MA</th>\n",
       "      <th>home.dest_Sweden / Arlington, NJ</th>\n",
       "      <th>home.dest_Sydney, Australia</th>\n",
       "      <th>home.dest_Vancouver, BC</th>\n",
       "      <th>home.dest_West Hampstead, London / Neepawa, MB</th>\n",
       "      <th>home.dest_West Kensington, London</th>\n",
       "      <th>home.dest_Weston-Super-Mare, Somerset</th>\n",
       "      <th>home.dest_Windsor, England New York, NY</th>\n",
       "      <th>home.dest_Winnipeg, MB</th>\n",
       "      <th>home.dest_Worcester, MA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.705118</td>\n",
       "      <td>1.185999</td>\n",
       "      <td>2.348632</td>\n",
       "      <td>2.496272</td>\n",
       "      <td>135.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2.238283</td>\n",
       "      <td>-0.617708</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>0.200751</td>\n",
       "      <td>22.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.515317</td>\n",
       "      <td>1.185999</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>4.205331</td>\n",
       "      <td>124.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.064070</td>\n",
       "      <td>-0.617708</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>-0.327976</td>\n",
       "      <td>148.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>0.587107</td>\n",
       "      <td>-0.617708</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>0.223057</td>\n",
       "      <td>208.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.417957</td>\n",
       "      <td>1.185999</td>\n",
       "      <td>0.998631</td>\n",
       "      <td>-0.588919</td>\n",
       "      <td>197.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.489747</td>\n",
       "      <td>-0.617708</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>-0.735231</td>\n",
       "      <td>51.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>3</td>\n",
       "      <td>0.048680</td>\n",
       "      <td>-0.617708</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>-0.738510</td>\n",
       "      <td>68.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.202586</td>\n",
       "      <td>2.989706</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>-0.734574</td>\n",
       "      <td>98.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.423021</td>\n",
       "      <td>-0.617708</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>-0.705330</td>\n",
       "      <td>89.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass       age     sibsp     parch      fare   body  sex_male  \\\n",
       "3          1 -0.705118  1.185999  2.348632  2.496272  135.0      True   \n",
       "9          1  2.238283 -0.617708 -0.351370  0.200751   22.0      True   \n",
       "10         1  0.515317  1.185999 -0.351370  4.205331  124.0      True   \n",
       "25         1 -1.064070 -0.617708 -0.351370 -0.327976  148.0      True   \n",
       "39         1  0.587107 -0.617708 -0.351370  0.223057  208.0      True   \n",
       "...      ...       ...       ...       ...       ...    ...       ...   \n",
       "748        3 -0.417957  1.185999  0.998631 -0.588919  197.0      True   \n",
       "781        3 -0.489747 -0.617708 -0.351370 -0.735231   51.0      True   \n",
       "797        3  0.048680 -0.617708 -0.351370 -0.738510   68.0      True   \n",
       "837        3 -0.202586  2.989706 -0.351370 -0.734574   98.0      True   \n",
       "1089       3 -1.423021 -0.617708 -0.351370 -0.705330   89.0      True   \n",
       "\n",
       "      embarked_Q  embarked_S  home.dest_Argentina  ...  \\\n",
       "3          False        True                False  ...   \n",
       "9          False       False                False  ...   \n",
       "10         False       False                False  ...   \n",
       "25         False       False                False  ...   \n",
       "39         False       False                False  ...   \n",
       "...          ...         ...                  ...  ...   \n",
       "748        False        True                False  ...   \n",
       "781        False       False                False  ...   \n",
       "797         True       False                False  ...   \n",
       "837        False        True                False  ...   \n",
       "1089       False        True                False  ...   \n",
       "\n",
       "      home.dest_Sweden  Worcester, MA  home.dest_Sweden / Arlington, NJ  \\\n",
       "3                               False                             False   \n",
       "9                               False                             False   \n",
       "10                              False                             False   \n",
       "25                              False                             False   \n",
       "39                              False                             False   \n",
       "...                               ...                               ...   \n",
       "748                             False                             False   \n",
       "781                             False                             False   \n",
       "797                             False                             False   \n",
       "837                             False                             False   \n",
       "1089                            False                             False   \n",
       "\n",
       "      home.dest_Sydney, Australia  home.dest_Vancouver, BC  \\\n",
       "3                           False                    False   \n",
       "9                           False                    False   \n",
       "10                          False                    False   \n",
       "25                          False                    False   \n",
       "39                          False                    False   \n",
       "...                           ...                      ...   \n",
       "748                         False                    False   \n",
       "781                         False                    False   \n",
       "797                         False                    False   \n",
       "837                         False                    False   \n",
       "1089                        False                    False   \n",
       "\n",
       "      home.dest_West Hampstead, London / Neepawa, MB  \\\n",
       "3                                              False   \n",
       "9                                              False   \n",
       "10                                             False   \n",
       "25                                             False   \n",
       "39                                             False   \n",
       "...                                              ...   \n",
       "748                                            False   \n",
       "781                                            False   \n",
       "797                                            False   \n",
       "837                                            False   \n",
       "1089                                           False   \n",
       "\n",
       "      home.dest_West Kensington, London  \\\n",
       "3                                 False   \n",
       "9                                 False   \n",
       "10                                False   \n",
       "25                                False   \n",
       "39                                False   \n",
       "...                                 ...   \n",
       "748                               False   \n",
       "781                               False   \n",
       "797                               False   \n",
       "837                               False   \n",
       "1089                              False   \n",
       "\n",
       "      home.dest_Weston-Super-Mare, Somerset  \\\n",
       "3                                     False   \n",
       "9                                     False   \n",
       "10                                    False   \n",
       "25                                    False   \n",
       "39                                    False   \n",
       "...                                     ...   \n",
       "748                                   False   \n",
       "781                                   False   \n",
       "797                                   False   \n",
       "837                                   False   \n",
       "1089                                  False   \n",
       "\n",
       "      home.dest_Windsor, England New York, NY  home.dest_Winnipeg, MB  \\\n",
       "3                                       False                   False   \n",
       "9                                       False                   False   \n",
       "10                                      False                   False   \n",
       "25                                      False                   False   \n",
       "39                                      False                   False   \n",
       "...                                       ...                     ...   \n",
       "748                                     False                   False   \n",
       "781                                     False                   False   \n",
       "797                                     False                   False   \n",
       "837                                     False                   False   \n",
       "1089                                    False                   False   \n",
       "\n",
       "      home.dest_Worcester, MA  \n",
       "3                       False  \n",
       "9                       False  \n",
       "10                      False  \n",
       "25                      False  \n",
       "39                      False  \n",
       "...                       ...  \n",
       "748                     False  \n",
       "781                     False  \n",
       "797                     False  \n",
       "837                     False  \n",
       "1089                    False  \n",
       "\n",
       "[73 rows x 76 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "bef9ea00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия пропущена из-за несбалансировки классов в выборке\n"
     ]
    }
   ],
   "source": [
    "# lr = LogisticRegression(max_iter=1000)\n",
    "# lr.fit(X_train, y_train)\n",
    "\n",
    "# lr_pred = lr.predict(X_test)\n",
    "# lr_acc = accuracy_score(y_test, lr_pred)\n",
    "\n",
    "# print(\"Logistic Regression Accuracy:\", lr_acc)\n",
    "print(\"Логистическая регрессия пропущена из-за несбалансировки классов в выборке\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4f7b9b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "gb = HistGradientBoostingClassifier(\n",
    "    max_iter=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "gb_pred = gb.predict(X_test)\n",
    "gb_acc = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "print(\"HistGradientBoosting Accuracy:\", gb_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "92af7ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM пропущен из-за несбалансировки классов в выборке\n"
     ]
    }
   ],
   "source": [
    "# svm = SVC(kernel=\"rbf\", probability=True)\n",
    "# svm.fit(X_train, y_train)\n",
    "\n",
    "# svm_pred = svm.predict(X_test)\n",
    "# svm_acc = accuracy_score(y_test, svm_pred)\n",
    "\n",
    "# print(\"SVM Accuracy:\", svm_acc)\n",
    "print(\"SVM пропущен из-за несбалансировки классов в выборке\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "734e58a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Model  Accuracy\n",
      "0  HistGradientBoosting       1.0\n",
      "\n",
      "Модель достигла 100.00% точности!\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"HistGradientBoosting\"],\n",
    "    \"Accuracy\": [gb_acc]\n",
    "})\n",
    "\n",
    "print(results)\n",
    "print(f\"\\nМодель достигла {gb_acc*100:.2f}% точности!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "85cc2818",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [15, 137, 15]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[173]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m cm = \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m sns.heatmap(cm, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, fmt=\u001b[33m\"\u001b[39m\u001b[33md\u001b[39m\u001b[33m\"\u001b[39m, cmap=\u001b[33m\"\u001b[39m\u001b[33mBlues\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mPredicted\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Desktop\\project\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Desktop\\project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:549\u001b[39m, in \u001b[36mconfusion_matrix\u001b[39m\u001b[34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[39m\n\u001b[32m    546\u001b[39m     sample_weight = _convert_to_numpy(sample_weight, xp)\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sample_weight) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m     y_type, y_true, y_pred, sample_weight = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    553\u001b[39m     \u001b[38;5;66;03m# This is needed to handle the special case where y_true, y_pred and\u001b[39;00m\n\u001b[32m    554\u001b[39m     \u001b[38;5;66;03m# sample_weight are all empty.\u001b[39;00m\n\u001b[32m    555\u001b[39m     \u001b[38;5;66;03m# In this case we don't pass sample_weight to _check_targets that would\u001b[39;00m\n\u001b[32m    556\u001b[39m     \u001b[38;5;66;03m# check that sample_weight is not empty and we don't reuse the returned\u001b[39;00m\n\u001b[32m    557\u001b[39m     \u001b[38;5;66;03m# sample_weight\u001b[39;00m\n\u001b[32m    558\u001b[39m     y_type, y_true, y_pred, _ = _check_targets(y_true, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Desktop\\project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:108\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred, sample_weight)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m \u001b[33;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \u001b[33;03msample_weight : array or None\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    107\u001b[39m xp, _ = get_namespace(y_true, y_pred, sample_weight)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m type_true = type_of_target(y_true, input_name=\u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    110\u001b[39m type_pred = type_of_target(y_pred, input_name=\u001b[33m\"\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Desktop\\project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:464\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    462\u001b[39m lengths = [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    465\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    466\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    467\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [15, 137, 15]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, rf_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix - Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4a8bb118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Models are already trained. This cell saves them for later use if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e1a12088",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- body\nFeature names seen at fit time, yet now missing:\n- home.dest_Aberdeen / Portland, OR\n- home.dest_Albany, NY\n- home.dest_Altdorf, Switzerland\n- home.dest_Amenia, ND\n- home.dest_Antwerp, Belgium / Stanton, OH\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[175]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Scale\u001b[39;00m\n\u001b[32m     25\u001b[39m sample_df[numeric_features] = scaler.transform(sample_df[numeric_features])\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m prediction = \u001b[43mrf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m probability = rf.predict_proba(sample_df)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSurvived:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mYES\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNO\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Desktop\\project\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:1635\u001b[39m, in \u001b[36mGradientBoostingClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1620\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m   1621\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Predict class for X.\u001b[39;00m\n\u001b[32m   1622\u001b[39m \n\u001b[32m   1623\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1633\u001b[39m \u001b[33;03m        The predicted values.\u001b[39;00m\n\u001b[32m   1634\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1635\u001b[39m     raw_predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_predictions.ndim == \u001b[32m1\u001b[39m:  \u001b[38;5;66;03m# decision_function already squeezed it\u001b[39;00m\n\u001b[32m   1637\u001b[39m         encoded_classes = (raw_predictions >= \u001b[32m0\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Desktop\\project\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:1588\u001b[39m, in \u001b[36mGradientBoostingClassifier.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[32m   1571\u001b[39m \n\u001b[32m   1572\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1586\u001b[39m \u001b[33;03m        array of shape (n_samples,).\u001b[39;00m\n\u001b[32m   1587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1588\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1589\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1590\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1591\u001b[39m     raw_predictions = \u001b[38;5;28mself\u001b[39m._raw_predict(X)\n\u001b[32m   1592\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_predictions.shape[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Desktop\\project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2877\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2793\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2794\u001b[39m     _estimator,\n\u001b[32m   2795\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2801\u001b[39m     **check_params,\n\u001b[32m   2802\u001b[39m ):\n\u001b[32m   2803\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2804\u001b[39m \n\u001b[32m   2805\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2875\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2876\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2877\u001b[39m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2878\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2879\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\OneDrive\\Desktop\\project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2729\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2726\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[32m   2727\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[33mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2729\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[31mValueError\u001b[39m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- body\nFeature names seen at fit time, yet now missing:\n- home.dest_Aberdeen / Portland, OR\n- home.dest_Albany, NY\n- home.dest_Altdorf, Switzerland\n- home.dest_Amenia, ND\n- home.dest_Antwerp, Belgium / Stanton, OH\n- ...\n"
     ]
    }
   ],
   "source": [
    "sample_passenger = {\n",
    "    \"pclass\": 3,\n",
    "    \"sex\": \"male\",\n",
    "    \"age\": 22.0,\n",
    "    \"sibsp\": 1,\n",
    "    \"parch\": 0,\n",
    "    \"fare\": 7.25,\n",
    "    \"embarked\": \"S\",\n",
    "    \"home.dest\": \"Unknown\"\n",
    "}\n",
    "\n",
    "sample_df = pd.DataFrame([sample_passenger])\n",
    "\n",
    "# One-hot encoding (train bilan mos bo'lishi shart!)\n",
    "sample_df = pd.get_dummies(sample_df, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Yo'q ustunlarni qo'shamiz\n",
    "for col in X.columns:\n",
    "    if col not in sample_df.columns:\n",
    "        sample_df[col] = 0\n",
    "\n",
    "sample_df = sample_df[X.columns]\n",
    "\n",
    "# Scale\n",
    "sample_df[numeric_features] = scaler.transform(sample_df[numeric_features])\n",
    "\n",
    "prediction = rf.predict(sample_df)\n",
    "probability = rf.predict_proba(sample_df)\n",
    "\n",
    "print(\"Survived:\", \"YES\" if prediction[0] == 1 else \"NO\")\n",
    "print(\"Probability:\", probability)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
